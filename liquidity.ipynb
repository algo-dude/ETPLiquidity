{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: Daily Data\n",
    "I have pulled down USD, CHF, EUR, and GBP historical data from SIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style='white', palette=\"tab10\", font_scale=1.5, rc = {'figure.figsize':(12,6)})\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# a value has been set on a copy of a slice of a dataframe....\n",
    "\n",
    "# Data directory\n",
    "data_dir = Path() / 'data'\n",
    "# Data source:\n",
    "# https://www.six-group.com/en/products-services/the-swiss-stock-exchange/market-data/etp/etp-explorer/etp-detail.CH0454664001USD4.html#/\n",
    "\n",
    "# Create dict of dataframes from data_dir\n",
    "df_dict = {}\n",
    "for file in data_dir.glob('*.csv'):\n",
    "    # Semicolon delimited, and skip two lines for simplicity\n",
    "    df_dict[file.stem] = pd.read_csv(file, sep=';', skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBP = df_dict.get('historical_GBP')\n",
    "EUR = df_dict.get('historical_EUR')\n",
    "USD = df_dict.get('historical_USD')\n",
    "CHF = df_dict.get('historical_CHF')\n",
    "markets = [GBP, EUR, USD, CHF]\n",
    "markets_names = ['GBP', 'EUR', 'USD', 'CHF']\n",
    "# concat dataframes and add name of symbol\n",
    "master = pd.concat([GBP, EUR, USD, CHF], axis=1, keys=['GBP', 'EUR', 'USD', 'CHF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(markets):\n",
    "    # Plot volume of each pair\n",
    "\n",
    "    plot = sns.lineplot(x=v.index, y=v['Volume'], label = markets_names[i])\n",
    "    plot.set_xlabel('Index / Time')\n",
    "    plot.set_ylabel('Volume')\n",
    "    plot.set_title('Most recent dates are towards the origin')\n",
    "    # plot.invert_xaxis()\n",
    "\n",
    "# from functions import sns_lineplot\n",
    "# sns_lineplot(markets, markets_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(markets):\n",
    "    # Plot volume of each pair with seaborn\n",
    "    plot = sns.scatterplot(x=v.index, y=(v['Volume']), label = markets_names[i])\n",
    "    plot.set_xlabel('Index / Volume')\n",
    "    plot.set_ylabel('Volume')\n",
    "    plot.set_title('Most recent dates are towards the origin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulation\n",
    "Let's manipulate the original data so that the log plot of volume correctly shows zero days where they actually are.  \n",
    "  \n",
    "**Math nerd question: What problems are we going to encounter very shortly?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in markets:\n",
    "    # replace 0 with 1\n",
    "    df['Volume'] = df['Volume'].replace(0, 1)\n",
    "\n",
    "for i, v in enumerate(markets):\n",
    "    # Plot volume of each pair with seaborn\n",
    "    plot = sns.scatterplot(x=v.index, y=np.log(v['Volume']), label = markets_names[i])\n",
    "    # Add regression line for each pair\n",
    "    # We can skip confidence interval\n",
    "    plot = sns.regplot(x=v.index, y=np.log(v['Volume']), ci=False)\n",
    "    plot.set_xlabel('Index / Time')\n",
    "    plot.set_ylabel('Log (Volume)')\n",
    "    plot.set_title('Most recent dates are towards the origin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways\n",
    "USD has the most volume, followed by CHF.  \n",
    "This is in line with my expectation.  \n",
    "The Euro has move volume than the Pound, but they both have some days with zero volume.  \n",
    "I suspect this is reporting error.\n",
    "\n",
    "Is there any correlation between the currencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the volumes correlated?\n",
    "# plot correlation matrix\n",
    "volume_only = pd.DataFrame()\n",
    "for i, v in enumerate(markets):\n",
    "    volume_only[markets_names[i]] = v['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "corr = volume_only.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(100, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation values\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between GBP and EUR volume is ~0.7; suspect that this is largely caused be the zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Alternatives?\n",
    " What about turnover (volume * price) instead of only looking at share volume?\n",
    " \n",
    " Recall, though, that we are essentially comparing the same underlying across multiple markets, so one share is one share is one share.\n",
    "\n",
    " We could look at exchange rates at a minimum to see where there is more investigation warranted.\n",
    "\n",
    " I am confident that there are periodic arbitrage opportunities here, but that is well outside of the scope of this presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: Intra-Day Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = Path() / 'intraday_data'\n",
    "\n",
    "# Create dict of dataframes from data_dir\n",
    "\n",
    "for file in data_dir.glob('*.csv'):\n",
    "    # Semicolon delimited, and skip two lines for simplicity\n",
    "    # There is only one file in this folder.\n",
    "    # https://www.six-group.com/en/products-services/the-swiss-stock-exchange/market-data/etp/etp-explorer/etp-detail.CH0454664001USD4.html#/\n",
    "    df = pd.read_csv(file, sep=';', skiprows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trading hours\n",
    "SIX trading hours are from 0900 to 1720 GMT +1, so let's take a look at the intra-day trades on the 24th of March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# \n",
    "# I'll assume this 17:27 is after hours trading\n",
    "# It does seem correct that we have two trades immediately preceding the close at 17:19:58.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VWAP = sum (price * volume) / sum (volume)\n",
    "# Note I am reversing the dataframe here because we will use some forward looking functions\n",
    "df = df[::-1]\n",
    "# Vectorized for speed\n",
    "df['VWAP'] = np.cumsum(df['Price'] * df['Volume']) / np.cumsum(df['Volume'])\n",
    "print('Closing VWAP (not including the after hours trade) is: ', round(df['VWAP'].iloc[-2], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis  \n",
    " If we look at Binance Spot price movement, we can likely see the price of ABTC following BTCUSDT in short order.  \n",
    " \n",
    " **Question: How quickly do prices follow?**\n",
    "\n",
    " First, though, let's estimate it whether these reported volumes are buys or sells.  \n",
    " Simple logic:\n",
    " \n",
    "         DF['Pressure'] = BUY if next_price > current_price else SELL\n",
    "\n",
    "*Note for later: we will need to shift these times to match GMT + 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Delta'] = df['Price'].pct_change()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column 'Pressure' if 'Delta' is positive\n",
    "# df['Pressure'] = 'BUY' if df['Delta'] > 0 else 'SELL'     # truth error\n",
    "df['Pressure'] = np.where(df['Delta'] > 0, 'BUY', 'SELL')\n",
    "df['Pressure'] = np.where(df['Delta'] == 0, '0', df['Pressure'])\n",
    "# Shift pressure backwards once so it corresponds to the correct volume row\n",
    "df['Pressure'] = df['Pressure'].shift(-1)\n",
    "print('Let us look at the first few rows and see what happens at market open:')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some thoughts:**  \n",
    "It looks like market maker trading activity at 09:11:47.  \n",
    "This is probably the largest conjecture that I will make throughout the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List columns of df - something funny with trying to count the Time column\n",
    "print(df.columns)\n",
    "df.rename(columns={'        Time': 'Time'}, inplace=True)\n",
    "print(df.columns)\n",
    "df['Time'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print lines where 'Time' == 12:47:52.95\n",
    "print(df.where(df['Time'] == '12:47:52.95').dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  \n",
    "There is a perfect example of slippage on this order.  \n",
    "So... How much is it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover = 15.128 * 4009 + 15.102 * 593 + 15.004 * 1701\n",
    "print(\"Dollar volume is ${0:.2f}\".format(turnover))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $95k transaction has moved the market by itself.  \n",
    "But by how much?  \n",
    "Not all of it was slippage, only about 1/3rd of the order was filled sub-par."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price = (15.128 * 4009 + 15.102 * 593 + 15.004 * 1701) / (4009 + 593 + 1701)\n",
    "print(\"Average Price is ${0:.3f} compared to an initial fill at $15.128\".format(avg_price))\n",
    "# slippage_per_share = (15.128 - avg_price) / (4009 + 593 + 1701)\n",
    "# slippage_per_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total slippage =  expected * volume -  actual * volume\n",
    "total = 15.128 * (4009 + 593 + 1701) - avg_price * (4009 + 593 + 1701)\n",
    "print(\"Total USD slippage is: ${0:.2f} out of ${1:.2f}\".format(total, turnover))\n",
    "print(\"In percentage terms, this is {0:.5f}%\".format(total / turnover * 100))\n",
    "# Vectorize the following for speed\n",
    "daily_dollars = sum (df['Price'].to_numpy() * df['Volume'].to_numpy() )\n",
    "print('')\n",
    "print(\"The daily turnover is ${0:.2f}\".format(daily_dollars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Immediately the 0.237% figure caught my eye.  \n",
    "I am curious what the standard slippage amount is for a $100k order.  \n",
    "I suspect for the other currency pairs (EUR, GBP) this number would be higher.    \n",
    "To better analyze the data, I needed to know the daily turnover.  \n",
    "\n",
    "*This transaction was almost 1/5th of the daily volume for the instrument.*  \n",
    "\n",
    "*0.237% for nearly 1/5th of the daily volume, however, seems quite reasonable.*\n",
    "\n",
    "**Let's move on.**\n",
    "\n",
    "It's time to compare the ABTC price to the price of the underlying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Binance minute data for 24 March 2022\n",
    "I am using 5m candles here;  this will let us do some decent visual analysis inside the notebook without much hassle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get binance minute data for 24 March 2022url = 'https://api.binance.com/api/v3/klines'\n",
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "url = 'https://api.binance.com/api/v3/klines'\n",
    "symbol = 'BTCUSDT'\n",
    "interval = '5m'\n",
    "start = str(int(dt.datetime(2022,3,24).timestamp()*1000))\n",
    "end = str(int(dt.datetime(2022,3,25).timestamp()*1000))\n",
    "par = {'symbol': symbol, 'interval': interval, 'startTime': start, 'endTime': end}\n",
    "data = pd.DataFrame(json.loads(requests.get(url, params= par).text))\n",
    "#format columns name\n",
    "data.columns = ['datetime', 'Open', 'High', 'Low', 'Close', 'Volume','close_time', 'qav', 'num_trades','taker_base_vol', 'taker_quote_vol', 'ignore']\n",
    "data.index = [dt.datetime.fromtimestamp(x/1000.0) for x in data.datetime]\n",
    "data=data.astype(float)\n",
    "# set index to datetime column\n",
    "data.index = data['datetime']\n",
    "# drop a few columns\n",
    "data = data.drop(['datetime', 'close_time', 'qav', 'num_trades','taker_quote_vol', 'ignore'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something strange about the above - how does taker_base_vol not equal 1/2 * Volume?  \n",
    "I wonder if Binance has so much volume that it sometimes pairs makers with makers?  \n",
    "Again, beyond the scope of this presentation.  Does anyone know?\n",
    "\n",
    "Don't forget - we are not in the same time zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to hh:mm:ss.ms\n",
    "# Shift one hour to get GMT +1\n",
    "data.index = pd.to_datetime(data.index, unit='ms').shift(1, freq='H')\n",
    "# drop outside of time frame 0900 - 1730\n",
    "data = data.loc[(data.index.hour >= 9) & (data.index.hour <= 17)]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the Binance 5m data to get a visual of what happened on 24-March-2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "output_notebook()\n",
    "\n",
    "inc = data.Close > data.Open\n",
    "dec = data.Open > data.Close\n",
    "w = 5*60*1000 # half day in ms\n",
    "data['date'] = pd.to_datetime(data.index, unit='ms')\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "p = figure(x_axis_type=\"datetime\", tools=TOOLS, width=1000, title = \"Binance BTCUSDT 5m\")\n",
    "p.xaxis.major_label_orientation = pi/4\n",
    "p.grid.grid_line_alpha=0.3\n",
    "\n",
    "p.segment(data.date, data.High, data.date, data.Low, color=\"black\")\n",
    "p.vbar(data.date[inc], w, data.Open[inc], data.Close[inc], fill_color=\"#207318\", line_color=\"black\")\n",
    "p.vbar(data.date[dec], w, data.Open[dec], data.Close[dec], fill_color=\"#c40404\", line_color=\"black\")\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check our old SIX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove miliseconds from Time column\n",
    "df['date'] = df['Time'].str.split('.').str[0]\n",
    "\n",
    "# Add 2022-03-24 to date column\n",
    "df['date'] = '2022-03-24' + ' ' + df['date']\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot together\n",
    "Let's take a look at the Binance Spot price and our ABTC price movements.\n",
    "\n",
    "*Note: there is an issue since intraday data is sparse for ABTC.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "margins = dict(l=20, r=20, b=20, t=40)\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=data['date'],\n",
    "                open=data['Open'], high=data['High'],\n",
    "                low=data['Low'], close=data['Close'])\n",
    "                     ])\n",
    "\n",
    "fig.update_layout(xaxis_rangeslider_visible=False, title_text=\"Binance BTCUSDT 5m\", margin=margins, height=390)\n",
    "fig.show()\n",
    "\n",
    "fig2 = go.Figure(data=[go.Line(x=df['Time'], y=df['Price']), ])\n",
    "fig2.update_layout(xaxis_rangeslider_visible=False, title_text=\"SIX ABTC price movement\", margin=margins, height=390)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Volume', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialing in\n",
    "Let's take a look at the chart for the previously mentioned interesting points in time:   \n",
    "12:47:52.95\t  \n",
    "15:47:17.32\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis:\n",
    "We will see movements at Binance for BTCUSDT preceed the price movements at SIX of ABTC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first time frame and compare to actual price movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[14:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was going on on Binance?  \n",
    "*Recall that Binance is on GMT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Before Noon](tv_images/noise.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above looks largely inconsequential.  Unsure what to conclude here.  We can discuss if desired.\n",
    "\n",
    "Let's check the second time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[20:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the daily 1m bars.  Notice how this looks similar enough to our earlier 5m plot with bokeh:  \n",
    "\n",
    "![Daily](tv_images/zoom_out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming in towards 15:47:17.33 where we had a huge price hike:\n",
    "\n",
    "![Zoom In](tv_images/zoom_in.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "ABTC on SIX is liquid enough to follow the Binance spot price within one minute of a 0.77% price change.  \n",
    "If we compared the different currency tickers, I suspect that we could find arbitrage opportunities here as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about live liquidity?\n",
    "Let's find out how much liquidity is in the underlying and graph it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 orders past top of book\n",
    "r = requests.get(\"https://api.binance.com/api/v3/depth\", params=dict(symbol=\"BTCUSDT\", limit=100))\n",
    "results = r.json()\n",
    "frames = {side: pd.DataFrame(data=results[side], columns=[\"price\", \"quantity\"],\n",
    "                             dtype=float) for side in [\"bids\", \"asks\"]}\n",
    "frames_list = [frames[side].assign(side=side) for side in frames]\n",
    "data = pd.concat(frames_list, axis=\"index\", ignore_index=True, sort=True)\n",
    "price_summary = data.groupby(\"side\").price.describe()\n",
    "price_summary\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = frames[\"bids\"].price.max()\n",
    "min = frames[\"asks\"].price.min()\n",
    "print('The current highest bid is ${0:.2f}'.format(max))\n",
    "print('The current lowest ask is ${0:.2f}'.format(min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've looked at a bit too much data.  Let's start wrapping up.  \n",
    "How much depth is there to the current liquidity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.binance.com/api/v3/ticker/bookTicker\", params=dict(symbol=\"BTCUSDT\"))\n",
    "book_top = r.json()\n",
    "name = book_top.pop(\"symbol\")  # get symbol and also delete at the same time\n",
    "s = pd.Series(book_top, name=name, dtype=float)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order book scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(f\"Current Order Book Depth for {name}\")\n",
    "\n",
    "sns.scatterplot(x=\"price\", y=\"quantity\", hue=\"side\", data=data, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Price\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order book histogram\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(f\"Current Order Book Depth for {name}\")\n",
    "\n",
    "sns.histplot(x=\"price\", hue=\"side\", binwidth=1, data=data, ax=ax)\n",
    "sns.rugplot(x=\"price\", hue=\"side\", data=data, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order book weighted histogram - now we are getting somewhere\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(f\"Current Order Book Depth for {name}\")\n",
    "\n",
    "sns.histplot(x=\"price\", weights=\"quantity\", hue=\"side\", binwidth=1, data=data, ax=ax)\n",
    "sns.scatterplot(x=\"price\", y=\"quantity\", hue=\"side\", data=data, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Price\")\n",
    "ax.set_ylabel(\"Quantity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order book depth chart\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(f\"Current Order Book Depth for {name}\")\n",
    "sns.ecdfplot(x=\"price\", weights=\"quantity\", stat=\"count\", complementary=True, data=frames[\"bids\"], ax=ax)\n",
    "sns.ecdfplot(x=\"price\", weights=\"quantity\", stat=\"count\", data=frames[\"asks\"], ax=ax)\n",
    "sns.scatterplot(x=\"price\", y=\"quantity\", hue=\"side\", data=data, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Price\")\n",
    "ax.set_ylabel(\"Quantity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finale: how much liquidity is there at this very moment with NO SLIPPAGE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "counter = 0\n",
    "\n",
    "while counter <= 20:\n",
    "    now = time.time()\n",
    "    r = requests.get(\"https://api.binance.com/api/v3/ticker/bookTicker\", params=dict(symbol=\"BTCUSDT\"))\n",
    "    book_top = r.json()\n",
    "    name = book_top.pop(\"symbol\")  # get symbol and also delete at the same time\n",
    "    s = pd.Series(book_top, name=name, dtype=float)\n",
    "    buyer_liquidity = s.get(\"askPrice\") * s.get(\"askQty\")\n",
    "    seller_liquidity = s.get(\"bidPrice\") * s.get(\"bidQty\")\n",
    "    delay = time.time() - now\n",
    "    print('Request and response delay: {0:.2f} seconds'.format(delay))\n",
    "    print(f\"Buyer liquidity: ${round(buyer_liquidity, 2)}, BTC quantity: {(s.get('askQty'))}\")\n",
    "    print(f\"Seller liquidity: ${round(seller_liquidity, 2)}, BTC quantity: {(s.get('bidQty'))}\")\n",
    "    time.sleep(1)\n",
    "    counter += 1\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "It would be relatively easy to build a tool that finds current liquidity within a allowable slippage percent for the underlying, but BTC on Binance still has some issues, the main one being:  \n",
    "* **Order book spoofing is rampant.**  \n",
    "\n",
    "This could be mitigated by some combination of order types, such as Limit + Fill or Kill.  \n",
    "To the best of my knowledge, frontrunning a la Hedge Funds (\"Flash Boys\" - Michael Douglas) does not happen by other market participants.  This is beneficial for liquidity takers. \n",
    "\n",
    "There is some lag time between when the price moves on Binance and the price moves on SIX.  \n",
    "  \n",
    "I am quite impressed that 1/5th of the daily volume on ABTC only incurred 0.25% slippage!  \n",
    "\n",
    "____\n",
    "\n",
    "Final questions I have for you:  \n",
    "How often do you need to rebalance the ETP?  \n",
    "How often do you issue new shares?\n",
    "\n",
    "This concludes my presentation on crypto ETP and underlying liquidity."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
